{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the dataset\n",
    "Attribute Information:\n",
    "\n",
    "1.\tlettr\tcapital letter\t(26 values from A to Z) \n",
    "2.\tx-box\thorizontal position of box\t(integer) \n",
    "3.\ty-box\tvertical position of box\t(integer) \n",
    "4.\twidth\twidth of box\t(integer) \n",
    "5.\thigh height of box\t(integer) \n",
    "6.\tonpix\ttotal # on pixels\t(integer) \n",
    "7.\tx-bar\tmean x of on pixels in box\t(integer) \n",
    "8.\ty-bar\tmean y of on pixels in box\t(integer) \n",
    "9.\tx2bar\tmean x variance\t(integer) \n",
    "10.\ty2bar\tmean y variance\t(integer) \n",
    "11.\txybar\tmean x y correlation\t(integer) \n",
    "12.\tx2ybr\tmean of x * x * y\t(integer) \n",
    "13.\txy2br\tmean of x * y * y\t(integer) \n",
    "14.\tx-ege\tmean edge count left to right\t(integer) \n",
    "15.\txegvy\tcorrelation of x-ege with y\t(integer) \n",
    "16.\ty-ege\tmean edge count bottom to top\t(integer) \n",
    "17.\tyegvx\tcorrelation of y-ege with x\t(integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.26666666666666666, 0.6, 0.4, 0.4, 0.13333333333333333, 0.6, 0.3333333333333333, 0.2, 0.06666666666666667, 0.5333333333333333, 0.06666666666666667, 0.5333333333333333, 0.13333333333333333, 0.4666666666666667, 0.13333333333333333, 0.5333333333333333]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "letters = [\n",
    "    'A',\n",
    "    'B',\n",
    "    'C',\n",
    "    'D',\n",
    "    'E',\n",
    "    'F',\n",
    "    'G',\n",
    "    'H',\n",
    "    'I',\n",
    "    'J',\n",
    "    'K',\n",
    "    'L',\n",
    "    'M',\n",
    "    'N',\n",
    "    'O',\n",
    "    'P',\n",
    "    'Q',\n",
    "    'R',\n",
    "    'S',\n",
    "    'T',\n",
    "    'U',\n",
    "    'V',\n",
    "    'W',\n",
    "    'X',\n",
    "    'Y',\n",
    "    'Z'\n",
    "]\n",
    "\n",
    "letterNums = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]\n",
    "\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data'\n",
    "df = pd.read_csv(url, header=None)\n",
    "df = df.sort_values([0]).rename(index=str, columns={0:\"letter\", 1:\"x-pos\", 2:\"y-pos\", 3:\"width\", 4:\"height\", 5:\"numPixels\", 6:\"meanXPixels\", 7:\"meanYPixels\", 8:\"meanXVar\", 9:\"meanYVar\", 10:\"meanXYCor\", 11:\"meanXXY\", 12:\"meanXYY\", 13:\"meanEdgeCnt\", 14:\"xEdgCorr\", 15:\"meanYEdge\", 16:\"yEdgeCorr\"})\n",
    "df['letter'].replace(letters, letterNums, inplace=True)\n",
    "\n",
    "\n",
    "# Normalize all values by max\n",
    "for i in range(16):\n",
    "    df['x-pos'].replace(i, i / max(df['x-pos']), inplace=True)\n",
    "    df['y-pos'].replace(i, i / max(df['y-pos']), inplace=True)\n",
    "    df['width'].replace(i, i / max(df['width']), inplace=True)\n",
    "    df['height'].replace(i, i / max(df['height']), inplace=True)\n",
    "    df['numPixels'].replace(i, i / max(df['numPixels']), inplace=True)\n",
    "    df['meanXPixels'].replace(i, i / max(df['meanXPixels']), inplace=True)\n",
    "    df['meanYPixels'].replace(i, i / max(df['meanYPixels']), inplace=True)\n",
    "    df['meanXVar'].replace(i, i / max(df['meanXVar']), inplace=True)\n",
    "    df['meanYVar'].replace(i, i / max(df['meanYVar']), inplace=True)\n",
    "    df['meanXYCor'].replace(i, i / max(df['meanXYCor']), inplace=True)\n",
    "    df['meanXXY'].replace(i, i / max(df['meanXXY']), inplace=True)\n",
    "    df['meanXYY'].replace(i, i / max(df['meanXYY']), inplace=True)\n",
    "    df['meanEdgeCnt'].replace(i, i / max(df['meanEdgeCnt']), inplace=True)\n",
    "    df['xEdgCorr'].replace(i, i / max(df['xEdgCorr']), inplace=True)\n",
    "    df['meanYEdge'].replace(i, i / max(df['meanYEdge']), inplace=True)\n",
    "    df['yEdgeCorr'].replace(i, i / max(df['yEdgeCorr']), inplace=True)\n",
    "                     \n",
    "\n",
    "letters_input = df.values.tolist()\n",
    "print(letters_input[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614], 'output': 0.7105668883115941, 'delta': -0.0005348048046610517}]\n",
      "[{'weights': [0.2550690257394217, 0.49543508709194095], 'output': 0.6213859615555266, 'delta': -0.14619064683582808}, {'weights': [0.4494910647887381, 0.651592972722763], 'output': 0.6573693455986976, 'delta': 0.0771723774346327}]\n"
     ]
    }
   ],
   "source": [
    "from math import exp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "learning_rates = [0.5,0.1,0.01,0.001]\n",
    "epochs = 10\n",
    "\n",
    "# Calculate neuron activation for input\n",
    "def activate(weights, inputs):\n",
    "    activation = weights[-1]\n",
    "    for i in range(len(weights) - 1):\n",
    "        activation += weights[i] * inputs[i]\n",
    "    return activation\n",
    "\n",
    "\n",
    "# Transfer neuron activation implements logistic function (sigmoid)\n",
    "def transfer(activation):\n",
    "    return 1.0 / (1.0 + exp(-activation))\n",
    "\n",
    "# Calculate derivative of neuron output\n",
    "def transfer_derivative(output):\n",
    "    return output * (1.0 - output)\n",
    "\n",
    "# Backpropagate error and store in neurons\n",
    "def backward_propagate_error(network, expected):\n",
    "    for i in reversed(range(len(network))):\n",
    "        layer = network[i]\n",
    "        errors = list()\n",
    "        if i != len(network) - 1:\n",
    "            for j in range(len(layer)):\n",
    "                error = 0.0\n",
    "                for neuron in network[i + 1]:\n",
    "                    error += (neuron['weights'][j] * neuron['delta'])\n",
    "                errors.append(error)\n",
    "        else:\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                errors.append(expected[j] - neuron['output'])\n",
    "        for j in range(len(layer)):\n",
    "            neuron = layer[j]\n",
    "            neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
    "\n",
    "def forward_propagate(network, row):\n",
    "    inputs = row\n",
    "    for layer in network:\n",
    "        new_inputs = []\n",
    "        for neuron in layer:\n",
    "            activation = activate(neuron['weights'], inputs)\n",
    "            neuron['output'] = transfer(activation)\n",
    "            new_inputs.append(neuron['output'])\n",
    "        inputs = new_inputs\n",
    "    return inputs\n",
    "\n",
    "# test backpropagation of error\n",
    "network = [[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}],\n",
    "\t\t[{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095]}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
    "expected = [0, 1]\n",
    "backward_propagate_error(network, expected)\n",
    "for layer in network:\n",
    "\tprint(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 2]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "expected = [1, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n",
    "predicted = [1, 0, 0, 1, 0, 0, 1, 1, 1, 0]\n",
    "results = confusion_matrix(expected, predicted)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  3  6]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# loading the iris dataset \n",
    "iris = datasets.load_iris() \n",
    "  \n",
    "# X -> features, y -> label \n",
    "X = iris.data \n",
    "y = iris.target \n",
    "  \n",
    "# dividing X, y into train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0) \n",
    "  \n",
    "# training a DescisionTreeClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "dtree_model = DecisionTreeClassifier(max_depth = 2).fit(X_train, y_train) \n",
    "dtree_predictions = dtree_model.predict(X_test) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, dtree_predictions) \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
